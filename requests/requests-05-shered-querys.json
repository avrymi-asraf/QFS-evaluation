[
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    },
    {
        "article": "articles/Attention-Is-All-You-Need.md",
        "query": "Mechanisms for achieving and leveraging effective computational depth, using \"hierarchical convergence\" to overcome the vanishing gradient and premature convergence problems in recurrent systems."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The methodology of using generative models to create adversarial evaluation datasets."
    },
    {
        "article": "articles/Evolutionary Computation LLM.md",
        "query": "The role and limitations of proprietary expert models in synthetic data generation for LLM research."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "A critique of model-specific conclusions in RL research, using the Qwen model family as a case study for how easily performance gains can be achieved with spurious signals."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "The divergent behaviors of different model families (Qwen, Llama, OLMo) under identical RLVR training, highlighting a fundamental lack of technique generalization."
    },
    {
        "article": "articles/Forget-What-You-Know-about-LLMs.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Hierarchical-Reasoning-Model.md",
        "query": "Mechanisms for achieving and leveraging effective computational depth, using \"hierarchical convergence\" to overcome the vanishing gradient and premature convergence problems in recurrent systems."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "The role and limitations of proprietary expert models in synthetic data generation for LLM research."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "The interplay between data quantity, quality, and complexity in fine-tuning language models for mathematical tasks."
    },
    {
        "article": "articles/Learn Beyond The Answer.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    },
    {
        "article": "articles/MemOS.md",
        "query": "The framework for accountable and governed memory in multi-agent systems."
    },
    {
        "article": "articles/MemOS.md",
        "query": "Mechanisms for the lifecycle and cross-type transformation of memory."
    },
    {
        "article": "articles/MemOS.md",
        "query": "The vision for a collaborative and decentralized memory sharing ecosystem."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "The mechanism by which initializing a student network in close proximity to a random teacher allows it to escape the teacher's poor minimum by navigating the flatter side of an asymmetric valley in the loss landscape."
    },
    {
        "article": "articles/Random Teachers are Good Teachers.md",
        "query": "A reframing of non-contrastive self-supervised learning where implicit regularization from the teacher-student optimization dynamic, rather than explicit data augmentation, serves as the primary driver of feature learning."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "Causes of optimization instability and performance degradation during RL fine-tuning of small language models."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "The impact of output length constraints on the stability and efficacy of training LLMs for complex reasoning tasks."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "Strategies for curating compact datasets by balancing problem difficulty to enhance RL training efficiency under resource constraints."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "The challenge of managing multilingual language drift when fine-tuning a foundational model for a monolingual reasoning task."
    },
    {
        "article": "articles/Reinforcement Learning for Reasoning in Small LLMs.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The influence of a model's pretrained latent abilities (like code reasoning) on the outcomes of reinforcement learning, irrespective of the reward signal's quality."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "A critique of model-specific conclusions in RL research, using the Qwen model family as a case study for how easily performance gains can be achieved with spurious signals."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The role of optimization algorithm artifacts, specifically the clipping mechanism in GRPO, in creating a directional training signal from pure noise."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "The divergent behaviors of different model families (Qwen, Llama, OLMo) under identical RLVR training, highlighting a fundamental lack of technique generalization."
    },
    {
        "article": "articles/Rethinking Training Signals in RLVR.md",
        "query": "An analysis of how superficial interventions, such as prompting or rewarding simple syntactic patterns, can elicit complex reasoning behaviors in certain models."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The divergent behaviors of different model families (Qwen, Llama, OLMo) under identical RLVR training, highlighting a fundamental lack of technique generalization."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "Mechanisms for achieving and leveraging effective computational depth, using \"hierarchical convergence\" to overcome the vanishing gradient and premature convergence problems in recurrent systems."
    },
    {
        "article": "articles/Task Singular Vectors.md",
        "query": "The role of optimization algorithm artifacts, specifically the clipping mechanism in GRPO, in creating a directional training signal from pure noise."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The paper as a solution to the geometric unidentifiability of representation spaces, resolved by imposing a causal structure."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The derivation of a semantically meaningful geometry from the statistical properties of the model's full vocabulary, rather than from its training data distribution."
    },
    {
        "article": "articles/The-Linear-Representation-Hypothesis.md",
        "query": "The article's use of counterfactuals as a formal language to ground and connect disparate intuitions about linear representations."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "The role and limitations of proprietary expert models in synthetic data generation for LLM research."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "The interplay between data quantity, quality, and complexity in fine-tuning language models for mathematical tasks."
    },
    {
        "article": "articles/distillation of SOTA embedding models.md",
        "query": "A comparative economic analysis of achieving state-of-the-art reasoning performance in small vs. large language models."
    }
]
