timestamp,run_name,branch,commit,article,query,max_iterations,meta_json
2025-08-16T07:47:33Z,exp-001,main,4c9f022f108f6cb362d7ea2d3e77cbaab275573b,/home/avreymi/code/QFS-code-and-evaluation/Query-Focused-Summarization/articals/Attention-Is-All-You-Need.pdf,What are the core innovations of the Transformer architecture and how do they replace recurrence?,,{}
2025-08-16T07:47:33Z,exp-001,main,4c9f022f108f6cb362d7ea2d3e77cbaab275573b,/home/avreymi/code/QFS-code-and-evaluation/Query-Focused-Summarization/articals/The Linear Representation Hypothesis.pdf,Summarize the linear representation hypothesis and its implications for neural network interpretability.,,{}
2025-08-16T08:13:42Z,exp-002,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/Query-Focused-Summarization/articals/Attention-Is-All-You-Need.pdf,What are the core innovations of the Transformer architecture and how do they replace recurrence?,,{}
2025-08-16T08:13:42Z,exp-002,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/Query-Focused-Summarization/articals/The Linear Representation Hypothesis.pdf,Summarize the linear representation hypothesis and its implications for neural network interpretability.,,{}
2025-08-16T16:33:39Z,first_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Attention-Is-All-You-Need.md,What are the core innovations of the Transformer architecture and how do they replace recurrence?,,{}
2025-08-16T16:33:39Z,first_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/The-Linear-Representation-Hypothesis.md,Summarize the linear representation hypothesis and its implications for neural network interpretability.,,{}
2025-08-16T16:33:39Z,first_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Forget-What-You-Know-about-LLMs.md,Discuss the limitations of traditional evaluation methods for LLMs and propose alternative approaches.,,{}
2025-08-16T16:33:39Z,first_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Hierarchical-Reasoning-Model.md,Explain the hierarchical reasoning model and its significance in understanding complex systems.,,{}
2025-08-17T07:58:59Z,secode_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Attention-Is-All-You-Need.md,What are the core innovations of the Transformer architecture and how do they replace recurrence?,,"{""meta"": ""{'key':'value', 'key2':'value'}""}"
2025-08-17T07:58:59Z,secode_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/The-Linear-Representation-Hypothesis.md,Summarize the linear representation hypothesis and its implications for neural network interpretability.,,"{""meta"": ""{'key':'value', 'key2':'value'}""}"
2025-08-17T07:58:59Z,secode_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Forget-What-You-Know-about-LLMs.md,Discuss the limitations of traditional evaluation methods for LLMs and propose alternative approaches.,,"{""meta"": ""{'key':'value', 'key2':'value'}""}"
2025-08-17T07:58:59Z,secode_run,main,44f67b3b8816d5393c6e95f8d9cdc8dfcd3fae19,/home/avreymi/code/QFS-code-and-evaluation/QFS-evaluation/articles/Hierarchical-Reasoning-Model.md,Explain the hierarchical reasoning model and its significance in understanding complex systems.,,"{""meta"": ""{'key':'value', 'key2':'value'}""}"
