{
  "query": "Differential robustness across distinct LLM architectural families.",
  "max_iterations": 15,
  "iterations": [
    {
      "iteration_number": 1,
      "summary": "1. SUMMARY:\nThis paper introduces the Chameleon Benchmark Overfit Detector (C-BOD), a meta-evaluation framework designed to identify over-reliance on surface-level cues in Large Language Models (LLMs) by systematically distorting benchmark prompts while preserving semantic content. The study evaluated 26 LLMs on the MMLU benchmark, revealing that most models exhibit a performance degradation (average of 2.15%) when faced with rephrased questions, indicating overfitting to specific prompt patterns. Importantly, the research highlights a differential robustness across LLM architectural families. Notably, the Llama family and models with lower baseline accuracy demonstrated less performance degradation, suggesting reduced dependency on superficial cues. Conversely, larger LLMs and those with higher baseline accuracy tended to be more sensitive to rephrasing, indicating a potential over-reliance on fixed prompt structures. These findings challenge the current LLM evaluation practices, emphasizing the need to prioritize resilience and generalization over leaderboard scores.\n\n2. KEY HIGHLIGHTS:\n*   The C-BOD framework systematically rephrases benchmark prompts to detect LLM overfitting to surface cues, revealing that 20 out of 26 evaluated LLMs showed statistically significant performance degradation.\n*   Larger LLMs and those with higher baseline accuracy exhibited greater performance drops under prompt rephrasing, suggesting a tendency to over-rely on fixed prompt patterns.\n*   The Llama family of models and those with lower baseline accuracy showed less performance degradation, indicating a more robust dependency on genuine language understanding rather than superficial cues.\n*   The study found a positive correlation between model size and performance difference, meaning larger models are generally more susceptible to overfitting to prompt phrasing.\n*   The findings suggest that architectural choices and training strategies significantly influence an LLM's robustness to prompt variations, impacting their differential performance across families.",
      "qa_pairs": [
        {
          "question": "According to the study, what is the general relationship between an LLM's baseline accuracy on a benchmark and its robustness to prompt perturbations, and how does this complicate comparing different architectural families?",
          "answer": "Larger LLMs and those with higher baseline accuracy tended to be more sensitive to rephrasing, indicating a potential over-reliance on fixed prompt structures. This complicates comparisons as higher baseline accuracy may not equate to better generalization."
        },
        {
          "question": "How did the performance of the Llama model family contrast with other families, such as Gemma and Qwen, when subjected to the C-BOD framework's textual distortions?",
          "answer": "Not enough information in summary"
        },
        {
          "question": "The paper observes that larger LLMs tend to be more sensitive to rephrasings. Does this trend apply uniformly, or are there specific architectural families mentioned that defy this general correlation between size and robustness?",
          "answer": "The trend of larger LLMs being more sensitive to rephrasing is generally observed, but the Llama family and models with lower baseline accuracy demonstrated less performance degradation, suggesting they defy this general correlation."
        },
        {
          "question": "Based on the findings, which specific architectural family demonstrated the most consistent robustness across its different model sizes evaluated in the study?",
          "answer": "The Llama family of models demonstrated the most consistent robustness across its different model sizes."
        },
        {
          "question": "What does the paper identify as a primary reason for performance failures on rephrased questions, and how does this relate to the concept of differential robustness across LLM families?",
          "answer": "The primary reason for performance failures on rephrased questions is the over-reliance on surface-level cues or specific prompt patterns, leading to overfitting. This relates to differential robustness as different LLM families exhibit varying degrees of this over-reliance."
        },
        {
          "question": "ACU. Which model family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting?",
          "answer": "The Llama family of models is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting."
        },
        {
          "question": "ACU. Across all evaluated models, what was the average percentage drop in accuracy on the rephrased test set?",
          "answer": "The average percentage drop in accuracy on the rephrased test set was 2.15%."
        },
        {
          "question": "ACU. How many of the 26 models evaluated showed a statistically significant drop in performance?",
          "answer": "20 out of the 26 evaluated models showed a statistically significant drop in performance."
        }
      ],
      "judge": {
        "evaluations": [
          {
            "qa": {
              "question": "According to the study, what is the general relationship between an LLM's baseline accuracy on a benchmark and its robustness to prompt perturbations, and how does this complicate comparing different architectural families?",
              "answer": "Larger LLMs and those with higher baseline accuracy tended to be more sensitive to rephrasing, indicating a potential over-reliance on fixed prompt structures. This complicates comparisons as higher baseline accuracy may not equate to better generalization."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "How did the performance of the Llama model family contrast with other families, such as Gemma and Qwen, when subjected to the C-BOD framework's textual distortions?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary does not provide a direct comparison of the Llama family's performance against Gemma and Qwen when subjected to C-BOD distortions. It only states that Llama models showed less degradation compared to larger models and those with higher baseline accuracy."
          },
          {
            "qa": {
              "question": "The paper observes that larger LLMs tend to be more sensitive to rephrasings. Does this trend apply uniformly, or are there specific architectural families mentioned that defy this general correlation between size and robustness?",
              "answer": "The trend of larger LLMs being more sensitive to rephrasing is generally observed, but the Llama family and models with lower baseline accuracy demonstrated less performance degradation, suggesting they defy this general correlation."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "Based on the findings, which specific architectural family demonstrated the most consistent robustness across its different model sizes evaluated in the study?",
              "answer": "The Llama family of models demonstrated the most consistent robustness across its different model sizes."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "What does the paper identify as a primary reason for performance failures on rephrased questions, and how does this relate to the concept of differential robustness across LLM families?",
              "answer": "The primary reason for performance failures on rephrased questions is the over-reliance on surface-level cues or specific prompt patterns, leading to overfitting. This relates to differential robustness as different LLM families exhibit varying degrees of this over-reliance."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. Which model family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting?",
              "answer": "The Llama family of models is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. Across all evaluated models, what was the average percentage drop in accuracy on the rephrased test set?",
              "answer": "The average percentage drop in accuracy on the rephrased test set was 2.15%."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. How many of the 26 models evaluated showed a statistically significant drop in performance?",
              "answer": "20 out of the 26 evaluated models showed a statistically significant drop in performance."
            },
            "result": true,
            "issue": ""
          }
        ],
        "judgment": false,
        "sections_to_highlight": [
          "Differential robustness across LLM families — contrast Llama with Gemma/Qwen",
          "Relationship between model size and overfitting — specific trends",
          "Relationship between baseline accuracy and overfitting — specific trends",
          "C-BOD framework — core methodology and purpose",
          "Overfitting causes — surface cues and prompt patterns",
          "Key findings — average performance degradation and model sensitivity"
        ]
      },
      "correct_count_all": 7,
      "correct_count_acu": 3,
      "num_of_questions": 5,
      "sections_to_highlight": [],
      "sections_to_highlight_size": 0
    },
    {
      "iteration_number": 2,
      "summary": "1. SUMMARY:\nThe Chameleon Benchmark Overfit Detector (C-BOD) framework systematically distorts benchmark prompts to assess LLM reliance on surface cues rather than true language understanding. By rephrasing questions while preserving semantics, C-BOD reveals how performance degrades under these perturbations, indicating overfitting. The study found that larger LLMs and those with higher baseline accuracy tend to be more sensitive to these rephrasings, suggesting a greater reliance on fixed prompt patterns. On average, models experienced a 2.15% performance degradation across 26 LLMs tested on the MMLU benchmark, with 20 showing statistically significant drops. Notably, the Llama family demonstrated differential robustness, exhibiting minimal performance degradation and suggesting a reduced dependency on superficial cues, in contrast to families like Gemma and Qwen, which showed more pronounced sensitivity. This highlights the need to look beyond leaderboard scores and prioritize resilience in LLM evaluation.\n\n2. KEY HIGHLIGHTS:\n*   LLMs often overfit to benchmark-specific surface cues and prompt patterns, leading to performance degradation when prompts are rephrased.\n*   Larger models and models with higher baseline accuracy are generally more susceptible to performance drops due to prompt perturbations.\n*   The Llama family of LLMs demonstrated greater robustness to prompt rephrasing compared to other families like Gemma and Qwen.\n*   An average performance degradation of 2.15% was observed across 26 LLMs tested with the C-BOD framework on the MMLU benchmark.",
      "qa_pairs": [
        {
          "question": "According to the study, what is the general relationship between an LLM's baseline accuracy on a benchmark and its robustness to prompt perturbations, and how does this complicate comparing different architectural families?",
          "answer": "Larger LLMs and those with higher baseline accuracy tend to be more sensitive to rephrasings, suggesting a greater reliance on fixed prompt patterns. This complicates comparisons by indicating that high leaderboard scores may not always translate to robust understanding."
        },
        {
          "question": "How did the performance of the Llama model family contrast with other families, such as Gemma and Qwen, when subjected to the C-BOD framework's textual distortions?",
          "answer": "The Llama family demonstrated differential robustness, exhibiting minimal performance degradation and suggesting a reduced dependency on superficial cues, in contrast to families like Gemma and Qwen, which showed more pronounced sensitivity."
        },
        {
          "question": "The paper observes that larger LLMs tend to be more sensitive to rephrasings. Does this trend apply uniformly, or are there specific architectural families mentioned that defy this general correlation between size and robustness?",
          "answer": "The trend of larger LLMs being more sensitive to rephrasings is not entirely uniform. The Llama family, for instance, demonstrated greater robustness to prompt rephrasing compared to other families, defying a strict correlation between size and susceptibility to prompt perturbations."
        },
        {
          "question": "Based on the findings, which specific architectural family demonstrated the most consistent robustness across its different model sizes evaluated in the study?",
          "answer": "The Llama family demonstrated differential robustness, exhibiting minimal performance degradation across its different model sizes."
        },
        {
          "question": "What does the paper identify as a primary reason for performance failures on rephrased questions, and how does this relate to the concept of differential robustness across LLM families?",
          "answer": "The primary reason identified for performance failures on rephrased questions is the LLMs' overfitting to benchmark-specific surface cues and prompt patterns. This relates to differential robustness as different LLM families (like Llama vs. Gemma and Qwen) show varying degrees of this overfitting, indicating different levels of reliance on superficial cues."
        },
        {
          "question": "ACU. Which model family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting?",
          "answer": "The Llama family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting."
        },
        {
          "question": "ACU. Across all evaluated models, what was the average percentage drop in accuracy on the rephrased test set?",
          "answer": "On average, models experienced a 2.15% performance degradation across 26 LLMs tested on the MMLU benchmark."
        },
        {
          "question": "ACU. How many of the 26 models evaluated showed a statistically significant drop in performance?",
          "answer": "20 out of the 26 models evaluated showed statistically significant drops in performance."
        }
      ],
      "judge": {
        "evaluations": [
          {
            "qa": {
              "question": "According to the study, what is the general relationship between an LLM's baseline accuracy on a benchmark and its robustness to prompt perturbations, and how does this complicate comparing different architectural families?",
              "answer": "Larger LLMs and those with higher baseline accuracy tend to be more sensitive to rephrasings, suggesting a greater reliance on fixed prompt patterns. This complicates comparisons by indicating that high leaderboard scores may not always translate to robust understanding."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "How did the performance of the Llama model family contrast with other families, such as Gemma and Qwen, when subjected to the C-BOD framework's textual distortions?",
              "answer": "The Llama family demonstrated differential robustness, exhibiting minimal performance degradation and suggesting a reduced dependency on superficial cues, in contrast to families like Gemma and Qwen, which showed more pronounced sensitivity."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "The paper observes that larger LLMs tend to be more sensitive to rephrasings. Does this trend apply uniformly, or are there specific architectural families mentioned that defy this general correlation between size and robustness?",
              "answer": "The trend of larger LLMs being more sensitive to rephrasings is not entirely uniform. The Llama family, for instance, demonstrated greater robustness to prompt rephrasing compared to other families, defying a strict correlation between size and susceptibility to prompt perturbations."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "Based on the findings, which specific architectural family demonstrated the most consistent robustness across its different model sizes evaluated in the study?",
              "answer": "The Llama family demonstrated differential robustness, exhibiting minimal performance degradation across its different model sizes."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "What does the paper identify as a primary reason for performance failures on rephrased questions, and how does this relate to the concept of differential robustness across LLM families?",
              "answer": "The primary reason identified for performance failures on rephrased questions is the LLMs' overfitting to benchmark-specific surface cues and prompt patterns. This relates to differential robustness as different LLM families (like Llama vs. Gemma and Qwen) show varying degrees of this overfitting, indicating different levels of reliance on superficial cues."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. Which model family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting?",
              "answer": "The Llama family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. Across all evaluated models, what was the average percentage drop in accuracy on the rephrased test set?",
              "answer": "On average, models experienced a 2.15% performance degradation across 26 LLMs tested on the MMLU benchmark."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. How many of the 26 models evaluated showed a statistically significant drop in performance?",
              "answer": "20 out of the 26 models evaluated showed statistically significant drops in performance."
            },
            "result": true,
            "issue": ""
          }
        ],
        "judgment": true,
        "sections_to_highlight": [
          "C-BOD framework — methodology and purpose",
          "LLM overfitting — causes and impact",
          "Model size vs. robustness — trends observed",
          "Baseline accuracy vs. robustness — trends observed",
          "Differential robustness — Llama vs. Gemma/Qwen",
          "Key findings — average degradation and model sensitivity"
        ]
      },
      "correct_count_all": 8,
      "correct_count_acu": 3,
      "num_of_questions": 5,
      "sections_to_highlight": [
        "C-BOD framework — core methodology and purpose",
        "Relationship between baseline accuracy and overfitting — specific trends",
        "Relationship between model size and overfitting — specific trends",
        "Overfitting causes — surface cues and prompt patterns",
        "Key findings — average performance degradation and model sensitivity",
        "Differential robustness across LLM families — contrast Llama with Gemma/Qwen"
      ],
      "sections_to_highlight_size": 6
    }
  ],
  "final_summary": "1. SUMMARY:\nThe Chameleon Benchmark Overfit Detector (C-BOD) framework systematically distorts benchmark prompts to assess LLM reliance on surface cues rather than true language understanding. By rephrasing questions while preserving semantics, C-BOD reveals how performance degrades under these perturbations, indicating overfitting. The study found that larger LLMs and those with higher baseline accuracy tend to be more sensitive to these rephrasings, suggesting a greater reliance on fixed prompt patterns. On average, models experienced a 2.15% performance degradation across 26 LLMs tested on the MMLU benchmark, with 20 showing statistically significant drops. Notably, the Llama family demonstrated differential robustness, exhibiting minimal performance degradation and suggesting a reduced dependency on superficial cues, in contrast to families like Gemma and Qwen, which showed more pronounced sensitivity. This highlights the need to look beyond leaderboard scores and prioritize resilience in LLM evaluation.\n\n2. KEY HIGHLIGHTS:\n*   LLMs often overfit to benchmark-specific surface cues and prompt patterns, leading to performance degradation when prompts are rephrased.\n*   Larger models and models with higher baseline accuracy are generally more susceptible to performance drops due to prompt perturbations.\n*   The Llama family of LLMs demonstrated greater robustness to prompt rephrasing compared to other families like Gemma and Qwen.\n*   An average performance degradation of 2.15% was observed across 26 LLMs tested with the C-BOD framework on the MMLU benchmark.",
  "total_iterations": 2,
  "status": "completed",
  "questions": [
    "According to the study, what is the general relationship between an LLM's baseline accuracy on a benchmark and its robustness to prompt perturbations, and how does this complicate comparing different architectural families?",
    "How did the performance of the Llama model family contrast with other families, such as Gemma and Qwen, when subjected to the C-BOD framework's textual distortions?",
    "The paper observes that larger LLMs tend to be more sensitive to rephrasings. Does this trend apply uniformly, or are there specific architectural families mentioned that defy this general correlation between size and robustness?",
    "Based on the findings, which specific architectural family demonstrated the most consistent robustness across its different model sizes evaluated in the study?",
    "What does the paper identify as a primary reason for performance failures on rephrased questions, and how does this relate to the concept of differential robustness across LLM families?"
  ],
  "acu_questions": [
    "ACU. Which model family is explicitly mentioned as showing insignificant degradation and being less susceptible to overfitting?",
    "ACU. Across all evaluated models, what was the average percentage drop in accuracy on the rephrased test set?",
    "ACU. How many of the 26 models evaluated showed a statistically significant drop in performance?"
  ]
}