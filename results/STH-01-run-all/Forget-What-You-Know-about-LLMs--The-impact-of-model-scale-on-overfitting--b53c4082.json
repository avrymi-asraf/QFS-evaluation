{
  "query": "The impact of model scale on overfitting vulnerability.",
  "max_iterations": 15,
  "iterations": [
    {
      "iteration_number": 1,
      "summary": "1. SUMMARY:\nThis paper introduces the Chameleon Benchmark Overfit Detector (C-BOD), a meta-evaluation framework designed to identify how susceptible Large Language Models (LLMs) are to overfitting on benchmark-specific cues. The core of C-BOD involves systematically rephrasing benchmark prompts while preserving their semantic meaning and correct answers. By evaluating LLMs on both original and rephrased prompts, the framework detects performance degradation that suggests reliance on superficial patterns rather than true language understanding. Experiments on the MMLU benchmark with 26 leading LLMs revealed that, on average, models experienced a 2.15% accuracy drop under modest perturbations, with 20 models showing statistically significant declines. Crucially, the study found that larger LLMs tend to be more sensitive to these rephrasings, indicating a greater vulnerability to overfitting. Conversely, models with lower baseline accuracy and the Llama family showed less degradation, suggesting reduced dependency on superficial cues. The findings challenge the LLM community to prioritize robustness and generalization over leaderboard scores.\n\n2. KEY HIGHLIGHTS:\n*   Larger LLMs tend to be more sensitive to prompt rephrasing, indicating a higher vulnerability to overfitting on benchmark-specific patterns.\n*   Models with higher baseline accuracy on standard benchmarks are more likely to exhibit significant performance drops when prompts are perturbed.\n*   The C-BOD framework reveals that a substantial portion of LLMs (20 out of 26 tested) overfit to benchmark-specific cues, leading to performance degradation when prompts are subtly altered.\n*   The Llama family of models demonstrated greater robustness to prompt variations, showing less performance degradation compared to many other LLMs.\n*   The research suggests that high benchmark scores may mask an overreliance on surface-level patterns rather than true language understanding, necessitating a shift in evaluation focus towards resilience.",
      "qa_pairs": [
        {
          "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
          "answer": "Larger LLMs tend to be more sensitive to prompt rephrasing, indicating a higher vulnerability to overfitting on benchmark-specific patterns."
        },
        {
          "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
          "answer": "The Llama family of models demonstrated greater robustness to prompt variations, showing less performance degradation compared to many other LLMs."
        },
        {
          "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
          "answer": "Not enough information in summary"
        },
        {
          "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
          "answer": "Models with higher baseline accuracy on standard benchmarks are more likely to exhibit significant performance drops when prompts are perturbed."
        },
        {
          "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
          "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger LLMs tend to be more sensitive to prompt rephrasing, indicating a higher vulnerability to overfitting on benchmark-specific patterns. High benchmark scores may mask an overreliance on surface-level patterns rather than true language understanding."
        },
        {
          "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
          "answer": "Not enough information in summary"
        },
        {
          "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
          "answer": "The Llama family of models demonstrated greater robustness to prompt variations, showing less performance degradation compared to many other LLMs."
        },
        {
          "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
          "answer": "Not enough information in summary"
        }
      ],
      "judge": {
        "evaluations": [
          {
            "qa": {
              "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
              "answer": "Larger LLMs tend to be more sensitive to prompt rephrasing, indicating a higher vulnerability to overfitting on benchmark-specific patterns."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
              "answer": "The Llama family of models demonstrated greater robustness to prompt variations, showing less performance degradation compared to many other LLMs."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary states there is a 'significant log-linear relationship' between performance difference and model size, implying that performance difference increases with model size in a logarithmic fashion. The summary does not explicitly state *how* the overfitting vulnerability changes, only that it increases logarithmically with size."
          },
          {
            "qa": {
              "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
              "answer": "Models with higher baseline accuracy on standard benchmarks are more likely to exhibit significant performance drops when prompts are perturbed."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
              "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger LLMs tend to be more sensitive to prompt rephrasing, indicating a higher vulnerability to overfitting on benchmark-specific patterns. High benchmark scores may mask an overreliance on surface-level patterns rather than true language understanding."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary does not contain the logarithmic fit equation or its coefficients. The article mentions '∆1.0 = 0.6318 · ln(# Params) + 0.7920', but this is not in the summary."
          },
          {
            "qa": {
              "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
              "answer": "The Llama family of models demonstrated greater robustness to prompt variations, showing less performance degradation compared to many other LLMs."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary does not mention the specific parameter count of the largest DeepSeek model. The article states 'DeepSeek 236B', but this is not in the summary."
          }
        ],
        "judgment": false,
        "sections_to_highlight": [
          "Model Size vs. Performance Degradation — log-linear relationship",
          "High Baseline Accuracy vs. Overfitting Vulnerability",
          "Llama Family Robustness — Insignificant Degradation",
          "C-BOD Framework — Detecting Overfitting"
        ]
      },
      "correct_count_all": 5,
      "correct_count_acu": 1,
      "num_of_questions": 5,
      "sections_to_highlight": [],
      "sections_to_highlight_size": 0
    },
    {
      "iteration_number": 2,
      "summary": "1. SUMMARY:\nThis paper introduces the Chameleon Benchmark Overfit Detector (C-BOD) framework to assess how LLMs overfit to specific prompt patterns in benchmarks. The study reveals that larger LLMs and those with higher baseline accuracy are generally more vulnerable to performance degradation when prompts are rephrased, indicating a reliance on surface cues rather than true understanding. Specifically, a log-linear relationship was observed between model size and performance difference, meaning larger models tend to show greater declines. In contrast, the Llama family of models, and those with lower baseline accuracy, demonstrated less significant performance drops, suggesting greater robustness. The research challenges the LLM community to move beyond leaderboard scores and prioritize evaluations that measure resilience and generalization, as high performance on standard benchmarks may mask underlying overfitting issues.\n\n2. KEY HIGHLIGHTS:\n*   Larger LLMs and those with higher baseline accuracy are more vulnerable to performance degradation when benchmark prompts are rephrased, indicating overfitting to surface cues.\n*   A log-linear relationship exists between model size and performance difference, with larger models showing greater sensitivity to prompt perturbations.\n*   The Llama family of models exhibited insignificant performance degradation across various scales, suggesting robustness against prompt rephrasing.\n*   C-BOD's findings suggest that high benchmark scores might not always reflect true language understanding but could be influenced by memorization of benchmark-specific patterns.",
      "qa_pairs": [
        {
          "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
          "answer": "Larger LLMs are generally more vulnerable to performance degradation when prompts are rephrased."
        },
        {
          "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
          "answer": "The Llama family of models demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes."
        },
        {
          "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
          "answer": "A log-linear relationship between model size and performance difference implies that larger models tend to show greater declines in performance when prompts are rephrased."
        },
        {
          "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
          "answer": "The article connects a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting by stating that models with higher baseline accuracy are generally more vulnerable to performance degradation when prompts are rephrased, indicating a reliance on surface cues."
        },
        {
          "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
          "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger models tend to be more vulnerable to performance degradation when prompts are rephrased, indicating overfitting to surface cues rather than true understanding."
        },
        {
          "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
          "answer": "Not enough information in summary"
        },
        {
          "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
          "answer": "The Llama family of models is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting."
        },
        {
          "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
          "answer": "Not enough information in summary"
        }
      ],
      "judge": {
        "evaluations": [
          {
            "qa": {
              "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
              "answer": "Larger LLMs are generally more vulnerable to performance degradation when prompts are rephrased."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
              "answer": "The Llama family of models demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
              "answer": "A log-linear relationship between model size and performance difference implies that larger models tend to show greater declines in performance when prompts are rephrased."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
              "answer": "The article connects a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting by stating that models with higher baseline accuracy are generally more vulnerable to performance degradation when prompts are rephrased, indicating a reliance on surface cues."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
              "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger models tend to be more vulnerable to performance degradation when prompts are rephrased, indicating overfitting to surface cues rather than true understanding."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary does not contain the specific coefficient value from the logarithmic fit equation."
          },
          {
            "qa": {
              "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
              "answer": "The Llama family of models is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
              "answer": "Not enough information in summary"
            },
            "result": false,
            "issue": "The summary does not mention the specific parameter count of the largest DeepSeek model."
          }
        ],
        "judgment": false,
        "sections_to_highlight": [
          "C-BOD Framework — Detecting Overfitting",
          "Model Size vs. Performance Degradation — log-linear relationship",
          "High Baseline Accuracy vs. Overfitting Vulnerability",
          "Llama Family Robustness — Insignificant Degradation",
          "Logarithmic Fit Equation Details",
          "DeepSeek Model Parameter Count"
        ]
      },
      "correct_count_all": 6,
      "correct_count_acu": 1,
      "num_of_questions": 5,
      "sections_to_highlight": [
        "C-BOD Framework — Detecting Overfitting",
        "High Baseline Accuracy vs. Overfitting Vulnerability",
        "Llama Family Robustness — Insignificant Degradation",
        "Model Size vs. Performance Degradation — log-linear relationship"
      ],
      "sections_to_highlight_size": 4
    },
    {
      "iteration_number": 3,
      "summary": "1. SUMMARY:\nThis research introduces the Chameleon Benchmark Overfit Detector (C-BOD) to assess how well Large Language Models (LLMs) generalize beyond specific prompt phrasing. The study found that many LLMs, especially larger ones and those with high baseline accuracy on benchmarks like MMLU, exhibit significant performance degradation when prompts are rephrased while preserving semantic meaning. This suggests these models overfit to surface-level cues. Notably, the Llama family models demonstrated robustness, showing insignificant performance drops, indicating reduced dependency on superficial patterns. The study identified a log-linear relationship between model size and performance degradation, described by the equation ∆1.0 = 0.6318 · ln(# Params) + 0.7920, meaning larger models tend to be more vulnerable to these rephrasings. DeepSeek models, including a 236B parameter version, were evaluated, with their performance degradation varying. The findings challenge the reliance on leaderboard scores and advocate for evaluations that prioritize resilience and generalization.\n\n2. KEY HIGHLIGHTS:\n*   The Llama family of models showed robust performance, exhibiting insignificant degradation when prompts were rephrased, suggesting reduced overfitting to benchmark-specific phrasing.\n*   A log-linear relationship was observed between model size (number of parameters) and performance degradation under rephrasing, with larger models tending to be more vulnerable.\n*   The study provides a logarithmic fit equation: ∆1.0 = 0.6318 · ln(# Params) + 0.7920, quantifying the relationship between model size and performance difference.\n*   LLMs with high baseline accuracy on original prompts were found to be more susceptible to performance drops when faced with rephrased inputs, indicating a potential overreliance on superficial cues.\n*   The C-BOD framework effectively detects overfitting by quantifying performance differences between original and semantically equivalent, but rephrased, benchmark prompts.",
      "qa_pairs": [
        {
          "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
          "answer": "The study identified a log-linear relationship between model size and performance degradation, with larger models tending to be more vulnerable to prompt rephrasing."
        },
        {
          "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
          "answer": "The Llama family of models demonstrated robustness, showing insignificant performance drops when prompts were rephrased."
        },
        {
          "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
          "answer": "This implies that as models get larger, their vulnerability to overfitting, as measured by performance degradation on rephrased prompts, increases at a rate proportional to the natural logarithm of their parameter count."
        },
        {
          "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
          "answer": "LLMs with high baseline accuracy on standard benchmarks were found to be more susceptible to performance drops when faced with rephrased inputs, indicating a potential overreliance on superficial cues."
        },
        {
          "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
          "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger models, despite high baseline accuracy, can overfit to surface-level cues and exhibit significant performance degradation when prompts are rephrased."
        },
        {
          "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
          "answer": "The coefficient applied to the natural log of the number of parameters is 0.6318."
        },
        {
          "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
          "answer": "The Llama family of models is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting."
        },
        {
          "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
          "answer": "The largest DeepSeek model evaluated in the study has 236 billion parameters."
        }
      ],
      "judge": {
        "evaluations": [
          {
            "qa": {
              "question": "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
              "answer": "The study identified a log-linear relationship between model size and performance degradation, with larger models tending to be more vulnerable to prompt rephrasing."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
              "answer": "The Llama family of models demonstrated robustness, showing insignificant performance drops when prompts were rephrased."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
              "answer": "This implies that as models get larger, their vulnerability to overfitting, as measured by performance degradation on rephrased prompts, increases at a rate proportional to the natural logarithm of their parameter count."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
              "answer": "LLMs with high baseline accuracy on standard benchmarks were found to be more susceptible to performance drops when faced with rephrased inputs, indicating a potential overreliance on superficial cues."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?",
              "answer": "Simply scaling up a model's parameter count may not automatically lead to more robust and generalizable language understanding because larger models, despite high baseline accuracy, can overfit to surface-level cues and exhibit significant performance degradation when prompts are rephrased."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
              "answer": "The coefficient applied to the natural log of the number of parameters is 0.6318."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
              "answer": "The Llama family of models is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting."
            },
            "result": true,
            "issue": ""
          },
          {
            "qa": {
              "question": "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?",
              "answer": "The largest DeepSeek model evaluated in the study has 236 billion parameters."
            },
            "result": true,
            "issue": ""
          }
        ],
        "judgment": true,
        "sections_to_highlight": [
          "Llama Family Robustness — Insignificant Degradation",
          "Model Size vs. Performance Degradation — log-linear relationship",
          "Logarithmic Fit Equation Details",
          "C-BOD Framework — Detecting Overfitting",
          "DeepSeek Model Parameter Count",
          "High Baseline Accuracy vs. Overfitting Vulnerability"
        ]
      },
      "correct_count_all": 8,
      "correct_count_acu": 3,
      "num_of_questions": 5,
      "sections_to_highlight": [
        "Llama Family Robustness — Insignificant Degradation",
        "Model Size vs. Performance Degradation — log-linear relationship",
        "Logarithmic Fit Equation Details",
        "C-BOD Framework — Detecting Overfitting",
        "DeepSeek Model Parameter Count",
        "High Baseline Accuracy vs. Overfitting Vulnerability"
      ],
      "sections_to_highlight_size": 6
    }
  ],
  "final_summary": "1. SUMMARY:\nThis research introduces the Chameleon Benchmark Overfit Detector (C-BOD) to assess how well Large Language Models (LLMs) generalize beyond specific prompt phrasing. The study found that many LLMs, especially larger ones and those with high baseline accuracy on benchmarks like MMLU, exhibit significant performance degradation when prompts are rephrased while preserving semantic meaning. This suggests these models overfit to surface-level cues. Notably, the Llama family models demonstrated robustness, showing insignificant performance drops, indicating reduced dependency on superficial patterns. The study identified a log-linear relationship between model size and performance degradation, described by the equation ∆1.0 = 0.6318 · ln(# Params) + 0.7920, meaning larger models tend to be more vulnerable to these rephrasings. DeepSeek models, including a 236B parameter version, were evaluated, with their performance degradation varying. The findings challenge the reliance on leaderboard scores and advocate for evaluations that prioritize resilience and generalization.\n\n2. KEY HIGHLIGHTS:\n*   The Llama family of models showed robust performance, exhibiting insignificant degradation when prompts were rephrased, suggesting reduced overfitting to benchmark-specific phrasing.\n*   A log-linear relationship was observed between model size (number of parameters) and performance degradation under rephrasing, with larger models tending to be more vulnerable.\n*   The study provides a logarithmic fit equation: ∆1.0 = 0.6318 · ln(# Params) + 0.7920, quantifying the relationship between model size and performance difference.\n*   LLMs with high baseline accuracy on original prompts were found to be more susceptible to performance drops when faced with rephrased inputs, indicating a potential overreliance on superficial cues.\n*   The C-BOD framework effectively detects overfitting by quantifying performance differences between original and semantically equivalent, but rephrased, benchmark prompts.",
  "total_iterations": 3,
  "status": "completed",
  "questions": [
    "What general trend does the article identify between the number of parameters in an LLM and its performance degradation when evaluated on rephrased prompts?",
    "According to the study, which specific model family demonstrates notable resistance to performance degradation from prompt perturbation across its different model sizes?",
    "The article describes the relationship between performance difference and model size as a \"significant log-linear relationship.\" What does this imply about the rate at which overfitting vulnerability changes as models get larger?",
    "How does the article connect a model's high baseline accuracy on a standard benchmark to its potential vulnerability to overfitting when faced with prompt variations?",
    "Based on the findings, why might simply scaling up a model's parameter count not automatically lead to more robust and generalizable language understanding?"
  ],
  "acu_questions": [
    "ACU. According to the logarithmic fit equation, what is the coefficient applied to the natural log of the number of parameters when calculating performance difference?",
    "ACU. Which model family is identified as maintaining relatively stable accuracy and showing insignificant degradation, suggesting less vulnerability to overfitting?",
    "ACU. How many parameters, in billions, does the largest DeepSeek model evaluated in the study have?"
  ]
}